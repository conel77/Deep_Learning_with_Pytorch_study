{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nys8hNWyXXCD"
      },
      "outputs": [],
      "source": [
        "#image training using pretrained-model(ResNet)\n",
        "\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3RXCnhTXejl",
        "outputId": "0432620f-3fcd-4288-8529-a861f41f8d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AlexNet',\n",
              " 'AlexNet_Weights',\n",
              " 'ConvNeXt',\n",
              " 'ConvNeXt_Base_Weights',\n",
              " 'ConvNeXt_Large_Weights',\n",
              " 'ConvNeXt_Small_Weights',\n",
              " 'ConvNeXt_Tiny_Weights',\n",
              " 'DenseNet',\n",
              " 'DenseNet121_Weights',\n",
              " 'DenseNet161_Weights',\n",
              " 'DenseNet169_Weights',\n",
              " 'DenseNet201_Weights',\n",
              " 'EfficientNet',\n",
              " 'EfficientNet_B0_Weights',\n",
              " 'EfficientNet_B1_Weights',\n",
              " 'EfficientNet_B2_Weights',\n",
              " 'EfficientNet_B3_Weights',\n",
              " 'EfficientNet_B4_Weights',\n",
              " 'EfficientNet_B5_Weights',\n",
              " 'EfficientNet_B6_Weights',\n",
              " 'EfficientNet_B7_Weights',\n",
              " 'EfficientNet_V2_L_Weights',\n",
              " 'EfficientNet_V2_M_Weights',\n",
              " 'EfficientNet_V2_S_Weights',\n",
              " 'GoogLeNet',\n",
              " 'GoogLeNetOutputs',\n",
              " 'GoogLeNet_Weights',\n",
              " 'Inception3',\n",
              " 'InceptionOutputs',\n",
              " 'Inception_V3_Weights',\n",
              " 'MNASNet',\n",
              " 'MNASNet0_5_Weights',\n",
              " 'MNASNet0_75_Weights',\n",
              " 'MNASNet1_0_Weights',\n",
              " 'MNASNet1_3_Weights',\n",
              " 'MaxVit',\n",
              " 'MaxVit_T_Weights',\n",
              " 'MobileNetV2',\n",
              " 'MobileNetV3',\n",
              " 'MobileNet_V2_Weights',\n",
              " 'MobileNet_V3_Large_Weights',\n",
              " 'MobileNet_V3_Small_Weights',\n",
              " 'RegNet',\n",
              " 'RegNet_X_16GF_Weights',\n",
              " 'RegNet_X_1_6GF_Weights',\n",
              " 'RegNet_X_32GF_Weights',\n",
              " 'RegNet_X_3_2GF_Weights',\n",
              " 'RegNet_X_400MF_Weights',\n",
              " 'RegNet_X_800MF_Weights',\n",
              " 'RegNet_X_8GF_Weights',\n",
              " 'RegNet_Y_128GF_Weights',\n",
              " 'RegNet_Y_16GF_Weights',\n",
              " 'RegNet_Y_1_6GF_Weights',\n",
              " 'RegNet_Y_32GF_Weights',\n",
              " 'RegNet_Y_3_2GF_Weights',\n",
              " 'RegNet_Y_400MF_Weights',\n",
              " 'RegNet_Y_800MF_Weights',\n",
              " 'RegNet_Y_8GF_Weights',\n",
              " 'ResNeXt101_32X8D_Weights',\n",
              " 'ResNeXt101_64X4D_Weights',\n",
              " 'ResNeXt50_32X4D_Weights',\n",
              " 'ResNet',\n",
              " 'ResNet101_Weights',\n",
              " 'ResNet152_Weights',\n",
              " 'ResNet18_Weights',\n",
              " 'ResNet34_Weights',\n",
              " 'ResNet50_Weights',\n",
              " 'ShuffleNetV2',\n",
              " 'ShuffleNet_V2_X0_5_Weights',\n",
              " 'ShuffleNet_V2_X1_0_Weights',\n",
              " 'ShuffleNet_V2_X1_5_Weights',\n",
              " 'ShuffleNet_V2_X2_0_Weights',\n",
              " 'SqueezeNet',\n",
              " 'SqueezeNet1_0_Weights',\n",
              " 'SqueezeNet1_1_Weights',\n",
              " 'SwinTransformer',\n",
              " 'Swin_B_Weights',\n",
              " 'Swin_S_Weights',\n",
              " 'Swin_T_Weights',\n",
              " 'Swin_V2_B_Weights',\n",
              " 'Swin_V2_S_Weights',\n",
              " 'Swin_V2_T_Weights',\n",
              " 'VGG',\n",
              " 'VGG11_BN_Weights',\n",
              " 'VGG11_Weights',\n",
              " 'VGG13_BN_Weights',\n",
              " 'VGG13_Weights',\n",
              " 'VGG16_BN_Weights',\n",
              " 'VGG16_Weights',\n",
              " 'VGG19_BN_Weights',\n",
              " 'VGG19_Weights',\n",
              " 'ViT_B_16_Weights',\n",
              " 'ViT_B_32_Weights',\n",
              " 'ViT_H_14_Weights',\n",
              " 'ViT_L_16_Weights',\n",
              " 'ViT_L_32_Weights',\n",
              " 'VisionTransformer',\n",
              " 'Wide_ResNet101_2_Weights',\n",
              " 'Wide_ResNet50_2_Weights',\n",
              " '_GoogLeNetOutputs',\n",
              " '_InceptionOutputs',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_api',\n",
              " '_meta',\n",
              " '_utils',\n",
              " 'alexnet',\n",
              " 'convnext',\n",
              " 'convnext_base',\n",
              " 'convnext_large',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'densenet',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'detection',\n",
              " 'efficientnet',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_v2_l',\n",
              " 'efficientnet_v2_m',\n",
              " 'efficientnet_v2_s',\n",
              " 'get_model',\n",
              " 'get_model_builder',\n",
              " 'get_model_weights',\n",
              " 'get_weight',\n",
              " 'googlenet',\n",
              " 'inception',\n",
              " 'inception_v3',\n",
              " 'list_models',\n",
              " 'maxvit',\n",
              " 'maxvit_t',\n",
              " 'mnasnet',\n",
              " 'mnasnet0_5',\n",
              " 'mnasnet0_75',\n",
              " 'mnasnet1_0',\n",
              " 'mnasnet1_3',\n",
              " 'mobilenet',\n",
              " 'mobilenet_v2',\n",
              " 'mobilenet_v3_large',\n",
              " 'mobilenet_v3_small',\n",
              " 'mobilenetv2',\n",
              " 'mobilenetv3',\n",
              " 'optical_flow',\n",
              " 'quantization',\n",
              " 'regnet',\n",
              " 'regnet_x_16gf',\n",
              " 'regnet_x_1_6gf',\n",
              " 'regnet_x_32gf',\n",
              " 'regnet_x_3_2gf',\n",
              " 'regnet_x_400mf',\n",
              " 'regnet_x_800mf',\n",
              " 'regnet_x_8gf',\n",
              " 'regnet_y_128gf',\n",
              " 'regnet_y_16gf',\n",
              " 'regnet_y_1_6gf',\n",
              " 'regnet_y_32gf',\n",
              " 'regnet_y_3_2gf',\n",
              " 'regnet_y_400mf',\n",
              " 'regnet_y_800mf',\n",
              " 'regnet_y_8gf',\n",
              " 'resnet',\n",
              " 'resnet101',\n",
              " 'resnet152',\n",
              " 'resnet18',\n",
              " 'resnet34',\n",
              " 'resnet50',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'resnext50_32x4d',\n",
              " 'segmentation',\n",
              " 'shufflenet_v2_x0_5',\n",
              " 'shufflenet_v2_x1_0',\n",
              " 'shufflenet_v2_x1_5',\n",
              " 'shufflenet_v2_x2_0',\n",
              " 'shufflenetv2',\n",
              " 'squeezenet',\n",
              " 'squeezenet1_0',\n",
              " 'squeezenet1_1',\n",
              " 'swin_b',\n",
              " 'swin_s',\n",
              " 'swin_t',\n",
              " 'swin_transformer',\n",
              " 'swin_v2_b',\n",
              " 'swin_v2_s',\n",
              " 'swin_v2_t',\n",
              " 'vgg',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'video',\n",
              " 'vision_transformer',\n",
              " 'vit_b_16',\n",
              " 'vit_b_32',\n",
              " 'vit_h_14',\n",
              " 'vit_l_16',\n",
              " 'vit_l_32',\n",
              " 'wide_resnet101_2',\n",
              " 'wide_resnet50_2']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = models.AlexNet()\n",
        "resnet = models.resnet101(pretrained=True)"
      ],
      "metadata": {
        "id": "Pyduw7-AXfxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-964voiXiBu",
        "outputId": "f6d8e54b-b5e5-4ef0-e8d7-2817022e34ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )])"
      ],
      "metadata": {
        "id": "c9WsO_WNXjOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = Image.open('dog.png')"
      ],
      "metadata": {
        "id": "3C1fMcUDabC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# upload = files.upload()"
      ],
      "metadata": {
        "id": "TSNKwkpgX25_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "def convert_png_to_jpg(path):\n",
        "    # jpg파일을 저장하기 위한 디렉토리의 생성\n",
        "    if not os.path.exists(path+'_jpg'):\n",
        "        os.mkdir(path+'_jpg') \n",
        "\n",
        "    # 모든 png 파일의 절대경로를 저장\n",
        "    all_image_files=glob.glob(path+'/*.png') \n",
        "\n",
        "    for file_path in all_image_files:                   # 모든 png파일 경로에 대하여\n",
        "        img = Image.open(file_path).convert('RGB')  # 이미지를 불러온다.\n",
        "\n",
        "        directories=file_path.split('/')                # 절대경로상의 모든 디렉토리를 얻어낸다.\n",
        "        directories[-2]+='_jpg'                     # 저장될 디렉토리의 이름 지정\n",
        "        directories[-1]=directories[-1][:-4]+'.jpg'  # 저장될 파일의 이름 지정\n",
        "        save_filepath='/'.join(directories)          # 절대경로명으로 바꾸기\n",
        "        img.save(save_filepath, quality=100)       # jpg파일로 저장한다."
      ],
      "metadata": {
        "id": "icd0RcX5Y8cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path='/dog.png'\n",
        "convert_png_to_jpg(path)"
      ],
      "metadata": {
        "id": "mqdtpjrDZQdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXMsoQwnZUuY",
        "outputId": "47595cd7-8f56-4ae5-dd10-1ea201b1d0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.PngImagePlugin.PngImageFile"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_t = preprocess(image)"
      ],
      "metadata": {
        "id": "mEFeqfWGYcP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YzHuMwuXlO4",
        "outputId": "39e74e98-224b-4352-9020-7bd5f0326803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "batch_t = torch.unsqueeze(img_t, 0)"
      ],
      "metadata": {
        "id": "RIXBEofyXnHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = resnet(batch_t)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIPdUZa_banl",
        "outputId": "33b5e185-b1d9-425e-d298-aaa9ec020dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.4803e+00, -1.6618e+00, -2.4515e+00, -3.2662e+00, -3.2466e+00,\n",
              "         -1.3611e+00, -2.0465e+00, -2.5112e+00, -1.3043e+00, -2.8900e+00,\n",
              "         -1.6862e+00, -1.3055e+00, -2.6129e+00, -2.9645e+00, -2.4300e+00,\n",
              "         -2.8143e+00, -3.3019e+00, -7.9404e-01, -6.5183e-01, -1.2308e+00,\n",
              "         -3.0193e+00, -3.9457e+00, -2.2675e+00, -1.0811e+00, -1.0232e+00,\n",
              "         -1.0442e+00, -3.0918e+00, -2.4613e+00, -2.1964e+00, -3.2354e+00,\n",
              "         -3.3013e+00, -1.8553e+00, -2.0921e+00, -2.1327e+00, -1.9102e+00,\n",
              "         -3.2403e+00, -1.1396e+00, -1.0925e+00, -1.2186e+00, -9.3332e-01,\n",
              "         -4.5093e-01, -1.5489e+00,  1.4161e+00,  1.0871e-01, -1.8442e+00,\n",
              "         -1.4806e+00,  9.6227e-01, -9.9456e-01, -3.0060e+00, -2.7384e+00,\n",
              "         -2.5798e+00, -2.0666e+00, -1.8022e+00, -1.9328e+00, -1.7726e+00,\n",
              "         -1.3041e+00, -4.5848e-01, -2.0537e+00, -3.2804e+00, -5.0451e-01,\n",
              "         -3.8174e-01, -1.1147e+00, -7.3998e-01, -1.4299e+00, -1.4883e+00,\n",
              "         -2.1073e+00, -1.7373e+00, -4.0412e-01, -1.9374e+00, -1.4862e+00,\n",
              "         -1.2102e+00, -1.3223e+00, -1.0832e+00,  7.9207e-02, -4.1344e-01,\n",
              "         -2.7477e-01, -8.5398e-01,  6.0364e-01, -8.9197e-01,  1.4761e+00,\n",
              "         -2.6427e+00, -3.6478e+00, -2.7066e-01, -1.2360e-01, -2.2445e+00,\n",
              "         -2.3425e+00, -1.4430e+00,  2.5264e-01, -1.0588e+00, -2.8812e+00,\n",
              "         -2.5145e+00, -2.2579e+00,  4.1647e-01, -1.3463e+00, -1.6449e-02,\n",
              "         -2.8798e+00, -5.5658e-01, -1.3859e+00, -2.9352e+00, -1.8880e+00,\n",
              "         -4.2244e+00, -2.9742e+00, -2.0298e+00, -2.3869e+00, -2.7324e+00,\n",
              "         -3.9905e+00, -3.6113e+00, -5.4423e-01, -1.0291e+00, -1.8998e+00,\n",
              "         -3.5611e+00, -1.5031e+00,  1.0660e+00, -7.1587e-01, -7.2612e-01,\n",
              "         -2.2173e+00, -2.2616e+00, -5.9990e-01, -1.4349e+00, -2.5965e+00,\n",
              "         -3.9844e+00, -9.4164e-01, -5.3676e-01, -8.4138e-01, -1.1660e+00,\n",
              "         -7.3556e-01, -1.1300e+00, -2.1074e+00, -4.0037e+00, -3.7229e-01,\n",
              "         -2.7179e+00, -2.9849e+00, -1.9127e+00, -1.8412e+00, -1.3001e+00,\n",
              "         -2.2268e+00, -2.0247e+00, -3.1761e+00, -3.2964e+00, -2.7923e+00,\n",
              "         -4.3191e-01, -3.7750e+00, -2.4832e+00, -2.6228e+00, -2.7499e+00,\n",
              "         -2.6306e+00, -3.2714e+00, -4.3249e+00, -4.2451e+00, -3.6207e+00,\n",
              "         -1.1967e+00,  2.3839e+00,  1.8833e+00,  2.2390e+00,  4.9467e+00,\n",
              "          9.9434e-01,  2.9570e+00,  8.5852e-01,  2.2356e+00,  6.1872e+00,\n",
              "          4.2074e+00,  4.6280e+00,  7.5066e+00,  4.3456e+00,  4.8873e+00,\n",
              "          5.8086e+00,  4.0282e+00,  3.5778e+00,  9.5398e+00,  1.0959e+00,\n",
              "          3.3065e+00,  1.9473e+00, -4.7347e-01,  1.4388e+00,  1.8860e+00,\n",
              "          5.5149e+00,  5.6885e+00,  2.1434e+00,  2.5016e+00,  6.2614e-01,\n",
              "          1.9095e+00,  1.4927e+00,  3.4522e+00,  4.0987e-01,  4.2790e+00,\n",
              "          4.3379e+00,  1.2945e+00,  1.6308e+00,  1.1426e+00,  2.1246e+00,\n",
              "          8.6190e-01,  3.0266e+00,  3.5030e+00,  2.7914e+00,  1.8812e+00,\n",
              "          1.3916e-01,  2.0182e+00,  2.6938e+00,  1.0643e+00,  1.9063e+00,\n",
              "          3.5028e+00,  2.2950e+00,  2.5388e+00,  1.3140e+00,  3.5698e+00,\n",
              "          7.7051e+00,  4.3443e+00,  1.5674e+01,  1.2140e+01,  5.2050e+00,\n",
              "          1.9331e+00,  5.4996e+00,  6.1745e+00,  7.5155e+00,  5.8567e+00,\n",
              "          6.9794e+00,  5.6891e+00,  2.6934e+00,  5.3248e+00,  9.8436e+00,\n",
              "          6.4168e+00,  2.4431e+00,  5.6031e+00,  3.4884e+00,  2.0732e+00,\n",
              "          1.3375e+00,  2.5550e+00,  5.7791e+00,  7.5825e-01,  1.0360e+00,\n",
              "          4.8250e+00,  5.9932e+00,  3.9907e+00, -1.7508e+00,  3.6606e+00,\n",
              "          2.8820e+00,  2.8978e+00,  1.3059e+00,  4.2622e+00,  4.0880e+00,\n",
              "          3.4181e+00,  2.3945e+00,  3.1604e-01,  8.7091e-01,  5.0895e+00,\n",
              "         -7.0908e-01,  1.9885e+00,  2.8699e+00,  2.5281e+00,  1.9253e+00,\n",
              "          6.5843e-01,  3.4956e+00, -5.6701e-01,  1.9219e+00,  5.0423e-01,\n",
              "          2.3949e+00,  3.4628e+00,  5.1851e+00,  1.8182e+00,  3.9127e+00,\n",
              "          4.3620e+00,  3.3723e-01, -4.6588e-01,  5.6958e+00,  3.7192e+00,\n",
              "          2.4205e+00,  3.6402e+00,  3.3705e+00, -9.3733e-01, -2.0590e-01,\n",
              "          1.3018e-01,  1.1554e+00, -4.0951e-02,  4.5523e+00, -1.8349e+00,\n",
              "         -2.6543e+00, -1.6859e+00, -6.3751e-01, -1.5596e+00, -2.1529e+00,\n",
              "         -1.0245e+00,  1.5312e+00,  7.6857e-01, -1.8030e+00,  6.9033e-01,\n",
              "          9.1473e-01, -2.0907e+00, -2.1250e+00, -1.5808e+00, -4.7830e+00,\n",
              "         -1.0396e+00, -9.7836e-01, -2.0528e+00,  1.9793e+00, -6.0107e-01,\n",
              "         -2.4964e+00, -1.4914e+00, -3.2041e+00, -1.9067e+00, -5.9215e-01,\n",
              "         -1.0509e+00,  1.3131e+00, -1.5027e+00, -2.0352e+00,  1.3009e+00,\n",
              "          3.9806e-01, -3.5442e-01,  7.1537e-01, -3.0086e-01, -7.6254e-01,\n",
              "         -5.4504e-01,  1.0533e+00,  1.1973e-01,  7.1265e-02,  1.3234e+00,\n",
              "         -2.0051e+00, -1.7127e+00,  1.1415e+00, -4.3746e-01,  2.9573e-01,\n",
              "         -1.4572e+00, -2.6234e+00, -2.5400e+00, -2.4128e-01, -2.3629e+00,\n",
              "         -1.5560e+00, -2.5256e+00, -8.0395e-01,  1.5960e-01, -2.8029e+00,\n",
              "         -1.8937e+00, -9.4297e-01, -3.8987e-01, -4.6732e-01, -7.8799e-01,\n",
              "         -2.5103e+00, -1.8726e+00, -2.1138e+00, -5.5075e-01,  1.8876e-01,\n",
              "         -2.0678e+00, -1.7942e+00, -2.4776e+00, -3.8874e+00, -4.4214e+00,\n",
              "         -2.1606e+00, -1.9960e+00, -3.7195e+00, -1.8627e+00, -3.3882e+00,\n",
              "         -2.0034e+00, -2.2823e+00, -8.3603e-01, -5.1364e-01, -2.9197e+00,\n",
              "         -1.6728e+00, -2.5686e-01, -2.7734e+00, -1.7911e+00,  1.1283e-01,\n",
              "         -2.1215e+00, -1.5402e+00, -1.2457e+00, -9.6399e-01, -2.4953e+00,\n",
              "         -1.3973e+00, -3.8589e+00, -4.3189e+00, -1.5287e+00, -1.9420e+00,\n",
              "         -3.0008e+00, -2.9597e+00, -4.8460e+00, -2.4737e+00, -1.4287e+00,\n",
              "         -2.9093e+00, -1.2882e+00, -6.0873e-01, -2.8312e+00, -1.8754e+00,\n",
              "         -2.3758e+00, -3.4176e+00, -2.5520e+00, -3.8709e+00, -4.4702e+00,\n",
              "         -3.5587e+00, -9.4389e-01, -2.3503e+00, -2.0270e+00, -1.8470e+00,\n",
              "         -3.2897e+00, -3.4712e+00, -2.8471e+00, -1.9893e+00, -3.7441e+00,\n",
              "         -1.1865e+00, -2.8282e+00,  2.2839e-01, -1.3325e-01, -3.1261e-01,\n",
              "          1.4785e-01,  1.7180e+00,  1.8871e+00, -3.1302e+00, -3.7345e+00,\n",
              "         -2.6754e+00, -6.7742e-01, -8.4727e-01, -1.3179e+00,  4.7847e-01,\n",
              "         -2.2918e+00,  4.7733e+00,  1.5100e+00, -1.5956e+00,  3.3496e+00,\n",
              "          3.0611e+00,  1.5253e+00,  6.8673e-01,  1.2918e+00,  1.6387e+00,\n",
              "          1.0631e-01,  1.3420e+00,  5.2414e-02,  1.0270e+00, -4.6863e-01,\n",
              "         -1.3585e+00,  5.7504e-01,  2.8775e-01,  2.8255e+00,  2.1875e+00,\n",
              "          1.8301e+00,  1.3566e+00,  1.0992e+00,  2.3172e+00,  6.4046e+00,\n",
              "          1.8630e+00,  6.0024e-01, -1.4953e+00, -1.9144e+00, -2.6436e+00,\n",
              "          1.5186e+00, -4.8838e-01, -1.0530e-01,  1.9803e+00, -1.7358e+00,\n",
              "          3.7236e-01,  1.6658e+00,  7.8257e-01,  2.1721e+00, -1.4210e+00,\n",
              "         -2.4550e+00,  4.6637e-01,  3.3418e+00, -2.8537e-01,  1.1941e-01,\n",
              "          1.1450e+00, -1.3834e+00,  1.5737e+00, -2.1716e+00, -4.2427e-01,\n",
              "         -1.4805e+00, -2.1745e+00,  2.7962e+00,  2.4990e+00,  1.9237e-01,\n",
              "          4.7498e-01, -1.9682e+00, -1.6105e+00, -7.3869e-01, -1.1794e+00,\n",
              "         -2.9532e-01, -1.4142e+00,  2.2398e+00, -4.3380e-01, -8.6286e-01,\n",
              "          4.0300e-01, -1.4318e+00, -3.1364e-01,  3.4846e+00,  4.3202e-01,\n",
              "          4.5058e-01, -1.1090e+00,  2.2513e-01, -2.6651e+00, -2.8278e+00,\n",
              "         -6.5790e-01, -3.0889e-01,  8.2096e-01,  1.8005e-01, -4.2284e-01,\n",
              "         -5.8541e-01, -2.7820e-01,  1.6590e+00,  8.7698e-02, -4.6728e-01,\n",
              "          1.1241e+00,  2.2742e+00, -1.0448e+00,  9.4819e-01,  9.9525e-01,\n",
              "         -2.5969e+00, -5.5236e-01,  2.1583e+00, -9.2215e-01,  4.7108e-02,\n",
              "         -3.8016e-01,  1.5210e+00, -1.0433e+00,  1.9041e+00,  1.4741e+00,\n",
              "         -4.3896e+00, -1.6206e-01, -1.5698e-01, -7.3738e-01,  1.8179e+00,\n",
              "          3.3264e+00,  7.3696e-01, -7.6419e-01,  1.5898e+00,  1.9445e+00,\n",
              "          1.2725e+00, -1.5624e+00,  2.2197e+00,  9.9570e-01, -6.3256e-01,\n",
              "         -1.4160e+00,  1.6144e+00,  4.5531e-02,  9.0731e-01,  9.5069e-01,\n",
              "          5.3562e-01,  4.4124e-01,  1.0358e+00,  6.5593e-01,  3.3626e+00,\n",
              "         -1.0299e+00, -2.8939e+00, -7.0227e-01, -8.1103e-01,  7.0547e+00,\n",
              "         -3.3097e+00,  1.3230e+00,  1.6968e+00,  3.7732e+00, -1.1723e+00,\n",
              "          5.7985e-01, -1.8231e+00, -1.3483e+00,  4.1487e-01,  2.6429e+00,\n",
              "          1.4418e+00,  7.9635e-01,  4.8719e+00,  1.5457e+00, -3.5932e+00,\n",
              "         -2.2285e+00, -1.3850e+00, -8.9728e-01,  2.1657e+00,  2.0583e+00,\n",
              "         -8.9567e-01, -1.7835e+00, -1.4516e+00,  1.0497e+00, -7.6032e-01,\n",
              "         -1.4353e+00,  4.7010e-01,  8.7255e-01,  6.7030e-01, -1.1902e+00,\n",
              "         -1.4175e+00, -8.4839e-01,  1.1901e+00, -1.8283e+00,  2.4775e+00,\n",
              "          3.4005e-01, -1.7652e+00, -9.1973e-01,  2.9893e+00,  2.2373e+00,\n",
              "         -8.1442e-01, -1.9843e+00,  9.2510e-01, -2.1452e+00,  1.8891e-02,\n",
              "          2.5441e-01, -1.1333e-01, -6.2533e-01,  8.0225e-01,  4.0010e+00,\n",
              "         -1.1935e+00,  2.6455e+00, -1.7860e+00,  7.5865e-01,  5.1593e-01,\n",
              "          2.4376e-03, -7.6760e-01,  4.8149e-01,  1.3055e+00,  8.0364e-01,\n",
              "         -6.1874e-01,  4.6970e-02,  2.6322e-01, -2.1400e+00, -1.3908e+00,\n",
              "         -4.0182e-02, -4.2920e-01,  4.6767e-01,  1.3024e+00,  7.5817e-01,\n",
              "          9.9857e-02, -1.0072e-01, -8.5241e-01,  8.6249e-01,  6.9517e-01,\n",
              "          2.1217e+00,  7.1266e-01, -1.9782e-01,  2.3986e+00,  1.8734e+00,\n",
              "          1.0993e+00,  1.0336e+00,  1.4353e+00, -4.9213e-02, -1.3295e-01,\n",
              "         -1.7147e+00, -1.2590e+00, -1.3166e+00, -3.4476e+00,  5.9193e-01,\n",
              "          1.0995e+00,  1.0987e-02, -3.7005e-01, -4.5369e-01, -4.2330e-01,\n",
              "         -1.5137e+00,  2.7933e-01, -2.0776e-01,  3.2132e+00,  1.8063e+00,\n",
              "         -1.5186e+00,  2.8835e+00, -7.4290e-01,  3.2128e-02, -7.0117e-02,\n",
              "         -1.0103e+00,  1.1795e+00,  5.9283e-01,  1.2191e-01, -3.4571e+00,\n",
              "          1.3048e+00,  3.9847e-01, -1.2731e+00, -1.2927e+00, -1.6408e+00,\n",
              "          1.9229e+00,  4.1588e-02, -9.8906e-01,  6.7141e-01,  2.8807e+00,\n",
              "          1.6977e+00,  2.2305e-01, -8.1440e-01, -2.0507e+00,  1.7015e+00,\n",
              "         -2.0312e-01,  7.4630e-01,  1.5227e+00, -1.4377e+00, -1.1784e+00,\n",
              "          5.1375e-01, -6.4234e-01,  3.8708e-02,  2.6664e+00, -1.6256e+00,\n",
              "         -3.3457e+00,  2.1520e+00,  8.6618e-01,  1.3850e+00, -3.4029e-01,\n",
              "          1.8385e-01,  1.4680e+00, -1.0961e+00,  1.8217e+00, -1.2748e+00,\n",
              "         -2.1175e+00, -8.4857e-01, -5.3657e-01, -1.2562e+00,  1.1329e+00,\n",
              "         -1.4191e+00, -7.6893e-01, -3.4133e-01,  2.1594e+00, -2.1836e-01,\n",
              "         -1.8166e+00,  9.8038e-02,  1.7366e+00,  1.6465e-01,  7.7769e-01,\n",
              "          4.7226e+00, -7.3754e-01, -1.6683e+00, -8.1360e-01, -1.4618e+00,\n",
              "          3.4068e+00,  5.3348e-01, -3.1106e-01, -5.0764e-01,  3.0037e-01,\n",
              "          1.8626e+00, -1.1852e+00, -2.0411e+00, -9.6967e-02, -7.1424e-01,\n",
              "         -2.5433e+00, -3.4144e-02,  7.6702e-01, -1.7948e+00,  2.9510e-01,\n",
              "         -1.0903e+00,  1.5320e+00,  2.8823e+00,  5.1182e-01, -7.6857e-01,\n",
              "         -9.0145e-01, -1.7196e+00, -1.0044e+00,  9.1568e-01, -9.2978e-02,\n",
              "         -2.3068e+00,  2.2911e+00,  9.5719e-01,  1.9917e+00, -1.6980e+00,\n",
              "          2.6118e+00,  3.7953e+00,  7.1091e-01, -2.2801e-03, -1.0275e+00,\n",
              "          2.1824e+00,  1.4127e+00,  4.7933e-01, -1.3249e+00, -9.0533e-01,\n",
              "          5.8118e-01, -6.0400e-01,  5.1155e-01,  1.1511e+00,  9.5682e-01,\n",
              "          2.7826e+00, -3.0976e+00,  3.5563e+00, -1.6181e-01, -4.6198e-02,\n",
              "         -2.0769e+00, -1.4204e+00,  2.9824e+00, -4.8723e-01,  2.1408e-01,\n",
              "         -1.3643e-01,  2.2942e+00,  3.4084e-01,  9.9796e-01, -1.1452e+00,\n",
              "          3.3055e+00, -1.8049e+00,  3.2445e+00, -1.6493e-01,  1.3805e+00,\n",
              "          6.5878e-01,  4.6122e-01, -7.8641e-01,  3.8983e-01,  1.9974e+00,\n",
              "          4.0911e-01,  2.4162e+00, -1.9111e+00,  8.1044e-02,  2.2694e+00,\n",
              "         -1.6680e+00, -7.0304e-01,  1.4299e+00,  1.4233e-02,  7.9249e-01,\n",
              "          2.9637e+00, -9.4825e-01, -1.3366e+00,  2.6750e-01,  2.3589e+00,\n",
              "          1.8983e+00,  1.8345e+00,  8.5127e-01,  4.2841e+00,  4.8082e-01,\n",
              "         -1.4365e+00, -4.8286e-01,  3.0412e+00, -8.2025e-01,  3.3065e+00,\n",
              "         -6.5939e-01, -2.6282e+00, -3.1888e+00, -2.9725e+00,  1.2156e+00,\n",
              "          5.6016e+00,  3.0274e-01, -3.1681e+00,  2.5582e+00, -3.3199e-01,\n",
              "          1.4820e-01,  2.3601e+00, -1.4552e+00,  3.3269e+00, -3.3744e+00,\n",
              "         -6.4104e-01,  1.1680e+00, -2.6107e+00,  1.6885e+00, -1.5028e+00,\n",
              "         -2.6845e+00, -3.6659e+00, -1.7394e+00,  1.1231e+00,  2.0104e+00,\n",
              "         -1.4943e-01,  1.3057e+00,  1.2092e+00,  2.6647e+00, -1.7969e+00,\n",
              "         -1.8525e+00,  1.5488e+00, -2.0861e+00, -2.3154e+00,  9.9215e-01,\n",
              "         -3.7871e+00, -1.1176e+00,  9.0636e-01, -3.2947e-01, -3.4544e+00,\n",
              "          2.0940e+00,  5.4372e-01,  6.0876e-01, -1.3066e-01,  7.9443e-01,\n",
              "          7.9938e-01,  1.0587e+00, -1.8372e+00,  2.8466e-01, -1.1158e+00,\n",
              "          8.0787e-01,  1.0870e+00,  8.9547e+00, -8.9419e-01, -9.3960e-01,\n",
              "          1.0807e+00, -4.1462e-01, -1.7524e+00,  9.1855e-02,  1.8185e-01,\n",
              "         -1.3849e+00,  8.8831e-01, -4.1253e-01, -7.7844e-01, -3.1265e+00,\n",
              "         -3.8734e-01,  1.8115e-01, -2.2122e+00,  2.8848e+00,  4.5000e-01,\n",
              "          1.4854e+00, -3.4138e+00,  1.4939e+00, -2.5266e+00, -2.9228e+00,\n",
              "         -7.6507e-01,  2.8269e+00, -1.1918e+00, -6.2602e-01,  3.6187e+00,\n",
              "          1.1527e+00,  1.1860e+00,  3.4149e+00,  9.2982e-01, -1.1376e+00,\n",
              "          1.0391e+00,  1.8575e-01, -7.4427e-01, -2.9312e+00, -1.6815e-01,\n",
              "          1.5624e+00, -4.5063e-01,  1.5997e+00,  1.0128e+00, -1.3146e+00,\n",
              "         -1.8426e+00, -4.7445e-01,  5.8991e-01,  2.3850e+00,  5.2548e-01,\n",
              "         -1.3760e+00, -2.3240e+00, -7.6861e-01,  1.2772e+00,  2.9579e+00,\n",
              "         -2.7968e-01, -5.9378e-01, -2.4310e-02, -7.2352e-01, -5.9500e-02,\n",
              "          2.7550e+00,  2.9499e-01, -1.1396e+00, -1.4785e+00, -4.3375e+00,\n",
              "         -3.2104e-01, -3.2125e-01, -2.0806e+00,  3.7004e-01, -1.4368e+00,\n",
              "         -6.1700e-01, -2.0341e+00, -8.6155e-01, -4.0387e-01, -3.2359e-01,\n",
              "         -1.8287e+00, -1.7554e+00, -6.5640e-01,  6.7694e-01,  3.7156e+00,\n",
              "          2.1207e+00,  4.0970e+00,  1.7257e+00,  8.5265e-01,  1.2722e+00,\n",
              "          1.0563e+00,  1.3809e+00,  1.2871e+00, -7.5314e-01,  2.2593e+00,\n",
              "          1.1952e-01, -7.3866e-01,  1.0060e+00,  8.5880e-01, -6.6744e-01,\n",
              "         -3.2016e-01, -1.5605e+00,  2.0461e+00,  2.4740e+00,  2.2464e-01,\n",
              "          7.4987e-01,  3.8843e-02, -1.7622e+00,  1.9534e+00,  4.5175e-01,\n",
              "          1.2086e+00,  7.3219e-01, -1.0001e+00,  1.2820e-01, -3.7380e-01,\n",
              "          9.6212e-02,  3.2060e+00,  6.5023e-01, -1.1252e-01,  8.9641e-01,\n",
              "         -5.2855e-02, -1.1585e+00,  1.4922e-01,  3.7309e-01,  8.7084e-01,\n",
              "         -1.9354e+00,  1.0733e-01, -1.5175e+00, -1.8582e+00, -3.8437e+00,\n",
              "          1.8629e-01, -2.9438e+00,  5.4171e-01, -7.8057e-01, -2.6016e+00,\n",
              "         -4.4594e+00,  5.5604e-01, -1.3140e+00, -3.8408e+00, -7.5988e-01,\n",
              "         -5.7457e-01, -2.5448e+00,  2.3831e+00,  6.1368e-01,  4.8295e-01,\n",
              "          2.8674e+00, -3.7442e+00,  1.5085e+00, -3.2500e+00, -2.4894e+00,\n",
              "         -3.3541e-01,  1.2856e-01, -1.1355e+00,  3.3969e+00,  4.4584e+00]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, index = torch.max(out, 1)"
      ],
      "metadata": {
        "id": "T2pAc6jYbc72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n"
      ],
      "metadata": {
        "id": "u-YQ4Qb5bgD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, indices = torch.sort(out, descending=True)"
      ],
      "metadata": {
        "id": "dNDduFhdbmqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqJkStR7bqKs",
        "outputId": "4cfd18e2-8099-454c-e044-63aa76442adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([207])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7L0zIlJbq59",
        "outputId": "4a92138d-9701-47d1-9529-c161824d4e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.6218e-07, 2.8483e-06, 1.2930e-06, 5.7253e-07, 5.8387e-07, 3.8472e-06,\n",
              "        1.9386e-06, 1.2181e-06, 4.0722e-06, 8.3405e-07, 2.7796e-06, 4.0673e-06,\n",
              "        1.1003e-06, 7.7414e-07, 1.3212e-06, 8.9958e-07, 5.5247e-07, 6.7832e-06,\n",
              "        7.8199e-06, 4.3827e-06, 7.3282e-07, 2.9019e-07, 1.5543e-06, 5.0904e-06,\n",
              "        5.3939e-06, 5.2817e-06, 6.8163e-07, 1.2804e-06, 1.6688e-06, 5.9041e-07,\n",
              "        5.5276e-07, 2.3471e-06, 1.8523e-06, 1.7785e-06, 2.2217e-06, 5.8754e-07,\n",
              "        4.8012e-06, 5.0330e-06, 4.4368e-06, 5.9013e-06, 9.5598e-06, 3.1885e-06,\n",
              "        6.1842e-05, 1.6730e-05, 2.3734e-06, 3.4141e-06, 3.9282e-05, 5.5508e-06,\n",
              "        7.4263e-07, 9.7054e-07, 1.1374e-06, 1.9001e-06, 2.4752e-06, 2.1720e-06,\n",
              "        2.5495e-06, 4.0732e-06, 9.4878e-06, 1.9248e-06, 5.6447e-07, 9.0611e-06,\n",
              "        1.0245e-05, 4.9222e-06, 7.1600e-06, 3.5915e-06, 3.3878e-06, 1.8243e-06,\n",
              "        2.6410e-06, 1.0018e-05, 2.1622e-06, 3.3950e-06, 4.4742e-06, 3.9997e-06,\n",
              "        5.0798e-06, 1.6244e-05, 9.9250e-06, 1.1401e-05, 6.3886e-06, 2.7444e-05,\n",
              "        6.1505e-06, 6.5665e-05, 1.0680e-06, 3.9090e-07, 1.1448e-05, 1.3262e-05,\n",
              "        1.5903e-06, 1.4419e-06, 3.5448e-06, 1.9320e-05, 5.2056e-06, 8.4140e-07,\n",
              "        1.2141e-06, 1.5692e-06, 2.2759e-05, 3.9047e-06, 1.4762e-05, 8.4254e-07,\n",
              "        8.6013e-06, 3.7531e-06, 7.9718e-07, 2.2717e-06, 2.1961e-07, 7.6664e-07,\n",
              "        1.9714e-06, 1.3793e-06, 9.7638e-07, 2.7747e-07, 4.0544e-07, 8.7082e-06,\n",
              "        5.3625e-06, 2.2450e-06, 4.2631e-07, 3.3380e-06, 4.3577e-05, 7.3348e-06,\n",
              "        7.2600e-06, 1.6342e-06, 1.5635e-06, 8.2367e-06, 3.5736e-06, 1.1185e-06,\n",
              "        2.7919e-07, 5.8524e-06, 8.7735e-06, 6.4696e-06, 4.6762e-06, 7.1917e-06,\n",
              "        4.8475e-06, 1.8241e-06, 2.7385e-07, 1.0342e-05, 9.9061e-07, 7.5851e-07,\n",
              "        2.2162e-06, 2.3804e-06, 4.0895e-06, 1.6189e-06, 1.9813e-06, 6.2651e-07,\n",
              "        5.5551e-07, 9.1959e-07, 9.7434e-06, 3.4421e-07, 1.2527e-06, 1.0894e-06,\n",
              "        9.5947e-07, 1.0810e-06, 5.6953e-07, 1.9861e-07, 2.1511e-07, 4.0165e-07,\n",
              "        4.5347e-06, 1.6279e-04, 9.8669e-05, 1.4083e-04, 2.1115e-03, 4.0562e-05,\n",
              "        2.8872e-04, 3.5411e-05, 1.4034e-04, 7.3001e-03, 1.0082e-03, 1.5353e-03,\n",
              "        2.7312e-02, 1.1575e-03, 1.9899e-03, 4.9993e-03, 8.4280e-04, 5.3715e-04,\n",
              "        2.0863e-01, 4.4898e-05, 4.0954e-04, 1.0519e-04, 9.3467e-06, 6.3263e-05,\n",
              "        9.8941e-05, 3.7271e-03, 4.4336e-03, 1.2798e-04, 1.8311e-04, 2.8068e-05,\n",
              "        1.0129e-04, 6.6768e-05, 4.7375e-04, 2.2609e-05, 1.0830e-03, 1.1487e-03,\n",
              "        5.4762e-05, 7.6653e-05, 4.7044e-05, 1.2560e-04, 3.5530e-05, 3.0956e-04,\n",
              "        4.9845e-04, 2.4466e-04, 9.8468e-05, 1.7247e-05, 1.1292e-04, 2.2192e-04,\n",
              "        4.3501e-05, 1.0097e-04, 4.9835e-04, 1.4894e-04, 1.9005e-04, 5.5843e-05,\n",
              "        5.3286e-04, 3.3308e-02, 1.1560e-03, 9.6293e+01, 2.8081e+00, 2.7340e-03,\n",
              "        1.0371e-04, 3.6706e-03, 7.2084e-03, 2.7557e-02, 5.2459e-03, 1.6121e-02,\n",
              "        4.4364e-03, 2.2183e-04, 3.0820e-03, 2.8267e-01, 9.1845e-03, 1.7271e-04,\n",
              "        4.0707e-03, 4.9121e-04, 1.1931e-04, 5.7165e-05, 1.9316e-04, 4.8540e-03,\n",
              "        3.2032e-05, 4.2287e-05, 1.8696e-03, 6.0130e-03, 8.1173e-04, 2.6056e-06,\n",
              "        5.8355e-04, 2.6788e-04, 2.7212e-04, 5.5392e-05, 1.0650e-03, 8.9473e-04,\n",
              "        4.5786e-04, 1.6452e-04, 2.0584e-05, 3.5852e-05, 2.4357e-03, 7.3847e-06,\n",
              "        1.0961e-04, 2.6463e-04, 1.8803e-04, 1.0290e-04, 2.8989e-05, 4.9478e-04,\n",
              "        8.5120e-06, 1.0256e-04, 2.4847e-05, 1.6459e-04, 4.7878e-04, 2.6800e-03,\n",
              "        9.2452e-05, 7.5083e-04, 1.1767e-03, 2.1025e-05, 9.4179e-06, 4.4664e-03,\n",
              "        6.1875e-04, 1.6885e-04, 5.7177e-04, 4.3660e-04, 5.8777e-06, 1.2214e-05,\n",
              "        1.7093e-05, 4.7650e-05, 1.4405e-05, 1.4234e-03, 2.3955e-06, 1.0557e-06,\n",
              "        2.7803e-06, 7.9326e-06, 3.1546e-06, 1.7430e-06, 5.3868e-06, 6.9386e-05,\n",
              "        3.2364e-05, 2.4731e-06, 2.9929e-05, 3.7458e-05, 1.8549e-06, 1.7922e-06,\n",
              "        3.0886e-06, 1.2562e-07, 5.3064e-06, 5.6414e-06, 1.9265e-06, 1.0861e-04,\n",
              "        8.2270e-06, 1.2362e-06, 3.3773e-06, 6.0918e-07, 2.2296e-06, 8.3008e-06,\n",
              "        5.2467e-06, 5.5792e-05, 3.3393e-06, 1.9608e-06, 5.5114e-05, 2.2344e-05,\n",
              "        1.0528e-05, 3.0688e-05, 1.1108e-05, 7.0003e-06, 8.7011e-06, 4.3027e-05,\n",
              "        1.6915e-05, 1.6115e-05, 5.6366e-05, 2.0206e-06, 2.7070e-06, 4.6993e-05,\n",
              "        9.6895e-06, 2.0171e-05, 3.4950e-06, 1.0888e-06, 1.1835e-06, 1.1790e-05,\n",
              "        1.4128e-06, 3.1660e-06, 1.2007e-06, 6.7163e-06, 1.7603e-05, 9.0992e-07,\n",
              "        2.2586e-06, 5.8446e-06, 1.0162e-05, 9.4044e-06, 6.8244e-06, 1.2193e-06,\n",
              "        2.3068e-06, 1.8125e-06, 8.6516e-06, 1.8124e-05, 1.8978e-06, 2.4951e-06,\n",
              "        1.2597e-06, 3.0760e-07, 1.8034e-07, 1.7296e-06, 2.0391e-06, 3.6384e-07,\n",
              "        2.3297e-06, 5.0678e-07, 2.0241e-06, 1.5314e-06, 6.5043e-06, 8.9787e-06,\n",
              "        8.0963e-07, 2.8170e-06, 1.1607e-05, 9.3719e-07, 2.5027e-06, 1.6799e-05,\n",
              "        1.7987e-06, 3.2165e-06, 4.3182e-06, 5.7231e-06, 1.2376e-06, 3.7107e-06,\n",
              "        3.1652e-07, 1.9981e-07, 3.2538e-06, 2.1521e-06, 7.4654e-07, 7.7784e-07,\n",
              "        1.1795e-07, 1.2647e-06, 3.5958e-06, 8.1811e-07, 4.1384e-06, 8.1643e-06,\n",
              "        8.8451e-07, 2.3005e-06, 1.3947e-06, 4.9207e-07, 1.1694e-06, 3.1273e-07,\n",
              "        1.7174e-07, 4.2735e-07, 5.8393e-06, 1.4307e-06, 1.9769e-06, 2.3667e-06,\n",
              "        5.5920e-07, 4.6640e-07, 8.7058e-07, 2.0528e-06, 3.5502e-07, 4.5812e-06,\n",
              "        8.8717e-07, 1.8857e-05, 1.3135e-05, 1.0978e-05, 1.7398e-05, 8.3640e-05,\n",
              "        9.9044e-05, 6.5594e-07, 3.5843e-07, 1.0337e-06, 7.6223e-06, 6.4316e-06,\n",
              "        4.0172e-06, 2.4215e-05, 1.5169e-06, 1.7754e-03, 6.7929e-05, 3.0432e-06,\n",
              "        4.2758e-04, 3.2042e-04, 6.8980e-05, 2.9821e-05, 5.4613e-05, 7.7258e-05,\n",
              "        1.6690e-05, 5.7423e-05, 1.5814e-05, 4.1909e-05, 9.3921e-06, 3.8574e-06,\n",
              "        2.6670e-05, 2.0010e-05, 2.5315e-04, 1.3376e-04, 9.3564e-05, 5.8272e-05,\n",
              "        4.5048e-05, 1.5227e-04, 9.0732e-03, 9.6687e-05, 2.7350e-05, 3.3642e-06,\n",
              "        2.2125e-06, 1.0670e-06, 6.8520e-05, 9.2084e-06, 1.3507e-05, 1.0873e-04,\n",
              "        2.6451e-06, 2.1777e-05, 7.9382e-05, 3.2821e-05, 1.3171e-04, 3.6236e-06,\n",
              "        1.2886e-06, 2.3924e-05, 4.2425e-04, 1.1281e-05, 1.6910e-05, 4.7159e-05,\n",
              "        3.7626e-06, 7.2403e-05, 1.7106e-06, 9.8181e-06, 3.4142e-06, 1.7058e-06,\n",
              "        2.4584e-04, 1.8264e-04, 1.8190e-05, 2.4130e-05, 2.0965e-06, 2.9981e-06,\n",
              "        7.1693e-06, 4.6138e-06, 1.1169e-05, 3.6484e-06, 1.4093e-04, 9.7250e-06,\n",
              "        6.3321e-06, 2.2455e-05, 3.5848e-06, 1.0967e-05, 4.8936e-04, 2.3116e-05,\n",
              "        2.3549e-05, 4.9505e-06, 1.8796e-05, 1.0444e-06, 8.8757e-07, 7.7725e-06,\n",
              "        1.1019e-05, 3.4106e-05, 1.7967e-05, 9.8321e-06, 8.3568e-06, 1.1362e-05,\n",
              "        7.8844e-05, 1.6382e-05, 9.4047e-06, 4.6184e-05, 1.4587e-04, 5.2790e-06,\n",
              "        3.8733e-05, 4.0599e-05, 1.1181e-06, 8.6377e-06, 1.2990e-04, 5.9676e-06,\n",
              "        1.5731e-05, 1.0261e-05, 6.8682e-05, 5.2865e-06, 1.0075e-04, 6.5535e-05,\n",
              "        1.8617e-07, 1.2762e-05, 1.2827e-05, 7.1787e-06, 9.2429e-05, 4.1777e-04,\n",
              "        3.1358e-05, 6.9888e-06, 7.3572e-05, 1.0490e-04, 5.3570e-05, 3.1460e-06,\n",
              "        1.3813e-04, 4.0617e-05, 7.9720e-06, 3.6419e-06, 7.5407e-05, 1.5706e-05,\n",
              "        3.7181e-05, 3.8830e-05, 2.5639e-05, 2.3330e-05, 4.2280e-05, 2.8917e-05,\n",
              "        4.3315e-04, 5.3582e-06, 8.3078e-07, 7.4352e-06, 6.6690e-06, 1.7382e-02,\n",
              "        5.4817e-07, 5.6344e-05, 8.1879e-05, 6.5311e-04, 4.6467e-06, 2.6798e-05,\n",
              "        2.4238e-06, 3.8971e-06, 2.2723e-05, 2.1090e-04, 6.3454e-05, 3.3276e-05,\n",
              "        1.9593e-03, 7.0403e-05, 4.1285e-07, 1.6161e-06, 3.7565e-06, 6.1179e-06,\n",
              "        1.3086e-04, 1.1755e-04, 6.1278e-06, 2.5219e-06, 3.5144e-06, 4.2872e-05,\n",
              "        7.0159e-06, 3.5723e-06, 2.4013e-05, 3.5911e-05, 2.9336e-05, 4.5644e-06,\n",
              "        3.6364e-06, 6.4244e-06, 4.9334e-05, 2.4114e-06, 1.7876e-04, 2.1085e-05,\n",
              "        2.5685e-06, 5.9821e-06, 2.9821e-04, 1.4058e-04, 6.6464e-06, 2.0631e-06,\n",
              "        3.7849e-05, 1.7564e-06, 1.5293e-05, 1.9354e-05, 1.3399e-05, 8.0298e-06,\n",
              "        3.3473e-05, 8.2015e-04, 4.5495e-06, 2.1144e-04, 2.5156e-06, 3.2045e-05,\n",
              "        2.5139e-05, 1.5043e-05, 6.9650e-06, 2.4288e-05, 5.5368e-05, 3.3520e-05,\n",
              "        8.0830e-06, 1.5728e-05, 1.9525e-05, 1.7656e-06, 3.7347e-06, 1.4416e-05,\n",
              "        9.7698e-06, 2.3955e-05, 5.5195e-05, 3.2030e-05, 1.6583e-05, 1.3569e-05,\n",
              "        6.3986e-06, 3.5552e-05, 3.0074e-05, 1.2524e-04, 3.0605e-05, 1.2313e-05,\n",
              "        1.6519e-04, 9.7700e-05, 4.5049e-05, 4.2185e-05, 6.3044e-05, 1.4286e-05,\n",
              "        1.3138e-05, 2.7016e-06, 4.2611e-06, 4.0223e-06, 4.7753e-07, 2.7124e-05,\n",
              "        4.5062e-05, 1.5172e-05, 1.0365e-05, 9.5334e-06, 9.8276e-06, 3.3029e-06,\n",
              "        1.9842e-05, 1.2191e-05, 3.7304e-04, 9.1362e-05, 3.2867e-06, 2.6826e-04,\n",
              "        7.1391e-06, 1.5497e-05, 1.3990e-05, 5.4640e-06, 4.8812e-05, 2.7149e-05,\n",
              "        1.6952e-05, 4.7302e-07, 5.5329e-05, 2.2353e-05, 4.2011e-06, 4.1199e-06,\n",
              "        2.9086e-06, 1.0266e-04, 1.5644e-05, 5.5814e-06, 2.9368e-05, 2.6753e-04,\n",
              "        8.1958e-05, 1.8757e-05, 6.6466e-06, 1.9306e-06, 8.2267e-05, 1.2248e-05,\n",
              "        3.1652e-05, 6.8797e-05, 3.5639e-06, 4.6185e-06, 2.5084e-05, 7.8944e-06,\n",
              "        1.5599e-05, 2.1592e-04, 2.9532e-06, 5.2876e-07, 1.2908e-04, 3.5683e-05,\n",
              "        5.9951e-05, 1.0678e-05, 1.8036e-05, 6.5137e-05, 5.0150e-06, 9.2773e-05,\n",
              "        4.1943e-06, 1.8057e-06, 6.4233e-06, 8.7751e-06, 4.2731e-06, 4.6593e-05,\n",
              "        3.6306e-06, 6.9557e-06, 1.0667e-05, 1.3004e-04, 1.2063e-05, 2.4398e-06,\n",
              "        1.6552e-05, 8.5207e-05, 1.7693e-05, 3.2661e-05, 1.6877e-03, 7.1775e-06,\n",
              "        2.8298e-06, 6.6519e-06, 3.4787e-06, 4.5272e-04, 2.5584e-05, 1.0995e-05,\n",
              "        9.0327e-06, 2.0264e-05, 9.6652e-05, 4.5875e-06, 1.9492e-06, 1.3620e-05,\n",
              "        7.3467e-06, 1.1796e-06, 1.4503e-05, 3.2315e-05, 2.4936e-06, 2.0158e-05,\n",
              "        5.0438e-06, 6.9440e-05, 2.6794e-04, 2.5036e-05, 6.9583e-06, 6.0924e-06,\n",
              "        2.6883e-06, 5.4965e-06, 3.7494e-05, 1.3674e-05, 1.4944e-06, 1.4835e-04,\n",
              "        3.9083e-05, 1.0996e-04, 2.7470e-06, 2.0445e-04, 6.6768e-04, 3.0551e-05,\n",
              "        1.4972e-05, 5.3706e-06, 1.3307e-04, 6.1632e-05, 2.4236e-05, 3.9893e-06,\n",
              "        6.0688e-06, 2.6834e-05, 8.2029e-06, 2.5029e-05, 4.7444e-05, 3.9069e-05,\n",
              "        2.4252e-04, 6.7765e-07, 5.2572e-04, 1.2765e-05, 1.4329e-05, 1.8806e-06,\n",
              "        3.6257e-06, 2.9615e-04, 9.2190e-06, 1.8589e-05, 1.3093e-05, 1.4881e-04,\n",
              "        2.1101e-05, 4.0709e-05, 4.7745e-06, 4.0912e-04, 2.4685e-06, 3.8492e-04,\n",
              "        1.2725e-05, 5.9681e-05, 2.8999e-05, 2.3801e-05, 6.8352e-06, 2.2161e-05,\n",
              "        1.1059e-04, 2.2592e-05, 1.6811e-04, 2.2198e-06, 1.6274e-05, 1.4518e-04,\n",
              "        2.8306e-06, 7.4294e-06, 6.2701e-05, 1.5222e-05, 3.3148e-05, 2.9066e-04,\n",
              "        5.8139e-06, 3.9427e-06, 1.9609e-05, 1.5877e-04, 1.0017e-04, 9.3976e-05,\n",
              "        3.5155e-05, 1.0886e-03, 2.4272e-05, 3.5679e-06, 9.2593e-06, 3.1411e-04,\n",
              "        6.6078e-06, 4.0952e-04, 7.7610e-06, 1.0836e-06, 6.1861e-07, 7.6795e-07,\n",
              "        5.0609e-05, 4.0649e-03, 2.0312e-05, 6.3154e-07, 1.9377e-04, 1.0767e-05,\n",
              "        1.7404e-05, 1.5896e-04, 3.5020e-06, 4.1795e-04, 5.1383e-07, 7.9047e-06,\n",
              "        4.8254e-05, 1.1027e-06, 8.1204e-05, 3.3390e-06, 1.0243e-06, 3.8389e-07,\n",
              "        2.6355e-06, 4.6136e-05, 1.1205e-04, 1.2924e-05, 5.5380e-05, 5.0285e-05,\n",
              "        2.1554e-04, 2.4884e-06, 2.3537e-06, 7.0615e-05, 1.8633e-06, 1.4816e-06,\n",
              "        4.0473e-05, 3.4008e-07, 4.9083e-06, 3.7146e-05, 1.0794e-05, 4.7430e-07,\n",
              "        1.2181e-04, 2.5847e-05, 2.7585e-05, 1.3169e-05, 3.3213e-05, 3.3377e-05,\n",
              "        4.3257e-05, 2.3901e-06, 1.9948e-05, 4.9172e-06, 3.3662e-05, 4.4500e-05,\n",
              "        1.1622e-01, 6.1368e-06, 5.8644e-06, 4.4219e-05, 9.9133e-06, 2.6014e-06,\n",
              "        1.6450e-05, 1.7999e-05, 3.7567e-06, 3.6481e-05, 9.9340e-06, 6.8899e-06,\n",
              "        6.5833e-07, 1.0187e-05, 1.7987e-05, 1.6426e-06, 2.6862e-04, 2.3535e-05,\n",
              "        6.6280e-05, 4.9394e-07, 6.6843e-05, 1.1994e-06, 8.0714e-07, 6.9826e-06,\n",
              "        2.5351e-04, 4.5571e-06, 8.0243e-06, 5.5961e-04, 4.7524e-05, 4.9133e-05,\n",
              "        4.5641e-04, 3.8028e-05, 4.8107e-06, 4.2421e-05, 1.8070e-05, 7.1294e-06,\n",
              "        8.0036e-07, 1.2684e-05, 7.1587e-05, 9.5627e-06, 7.4303e-05, 4.1317e-05,\n",
              "        4.0305e-06, 2.3771e-06, 9.3376e-06, 2.7070e-05, 1.6297e-04, 2.5380e-05,\n",
              "        3.7905e-06, 1.4689e-06, 6.9580e-06, 5.3825e-05, 2.8899e-04, 1.1345e-05,\n",
              "        8.2872e-06, 1.4646e-05, 7.2788e-06, 1.4140e-05, 2.3591e-04, 2.0156e-05,\n",
              "        4.8014e-06, 3.4212e-06, 1.9613e-07, 1.0886e-05, 1.0884e-05, 1.8736e-06,\n",
              "        2.1727e-05, 3.5669e-06, 8.0970e-06, 1.9629e-06, 6.3404e-06, 1.0020e-05,\n",
              "        1.0858e-05, 2.4105e-06, 2.5937e-06, 7.7842e-06, 2.9531e-05, 6.1653e-04,\n",
              "        1.2511e-04, 9.0283e-04, 8.4286e-05, 3.5203e-05, 5.3556e-05, 4.3155e-05,\n",
              "        5.9706e-05, 5.4356e-05, 7.0664e-06, 1.4370e-04, 1.6912e-05, 7.1695e-06,\n",
              "        4.1039e-05, 3.5421e-05, 7.6988e-06, 1.0895e-05, 3.1520e-06, 1.1612e-04,\n",
              "        1.7812e-04, 1.8786e-05, 3.1765e-05, 1.5601e-05, 2.5761e-06, 1.0583e-04,\n",
              "        2.3576e-05, 5.0256e-05, 3.1208e-05, 5.5203e-06, 1.7059e-05, 1.0326e-05,\n",
              "        1.6522e-05, 3.7038e-04, 2.8752e-05, 1.3410e-05, 3.6778e-05, 1.4234e-05,\n",
              "        4.7117e-06, 1.7422e-05, 2.1793e-05, 3.5850e-05, 2.1664e-06, 1.6707e-05,\n",
              "        3.2905e-06, 2.3403e-06, 3.2136e-07, 1.8080e-05, 7.9033e-07, 2.5796e-05,\n",
              "        6.8752e-06, 1.1128e-06, 1.7361e-07, 2.6168e-05, 4.0331e-06, 3.2231e-07,\n",
              "        7.0189e-06, 8.4480e-06, 1.1778e-06, 1.6266e-04, 2.7720e-05, 2.4324e-05,\n",
              "        2.6399e-04, 3.5499e-07, 6.7830e-05, 5.8190e-07, 1.2449e-06, 1.0730e-05,\n",
              "        1.7065e-05, 4.8209e-06, 4.4827e-04, 1.2959e-03],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Po757kSbsD9",
        "outputId": "f4233d1d-7c08-4379-f5c6-da6cedba3018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[207, 208, 219, 168, 852, 205, 213, 162, 539, 215, 220, 434, 159, 212,\n",
              "         231, 214, 165, 227, 263, 216, 176, 222, 805, 175, 211, 218, 209, 257,\n",
              "         244, 154, 164, 552, 230, 411, 700, 161, 273, 999, 260, 163, 206, 185,\n",
              "         793, 184, 238, 160, 931, 239, 166, 589, 232, 259, 736, 543, 264, 929,\n",
              "         234, 266, 879, 167, 204, 752, 192, 200, 251, 223, 478, 256, 182, 240,\n",
              "         882, 705, 998, 267, 534, 414, 452, 813, 515, 170, 799, 765, 767, 638,\n",
              "         961, 415, 797, 191, 578, 757, 785, 904, 156, 236, 868, 641, 722, 235,\n",
              "         659, 247, 990, 876, 428, 462, 193, 750, 910, 197, 217, 673, 828, 591,\n",
              "         549, 735, 808, 226, 202, 248, 178, 463, 574, 948, 221, 265, 776, 618,\n",
              "         255, 241, 898, 151, 987, 811, 789, 433, 201, 761, 731, 496, 779, 939,\n",
              "         472, 153, 579, 158, 522, 429, 740, 448, 558, 693, 502, 676, 177, 189,\n",
              "         615, 930, 840, 224, 559, 947, 196, 824, 774, 733, 246, 443, 293, 953,\n",
              "         171, 519, 210, 249, 655, 253, 180, 199, 508, 790, 402, 174, 152, 194,\n",
              "         619, 435, 710, 791, 430, 683, 258, 514, 639, 697, 932, 401, 664, 660,\n",
              "         542, 818, 446, 492, 419, 187, 526, 892, 518, 457, 890, 831, 553, 721,\n",
              "         281, 416, 667, 506, 440, 412, 992, 872, 181, 870,  79, 509, 681, 550,\n",
              "         173, 622, 782,  42, 741, 678, 936, 769, 431, 421, 225, 314, 541, 203,\n",
              "         301, 237, 826, 598, 650, 608, 304, 186, 418, 937, 903, 520, 934, 804,\n",
              "         827, 955, 572, 881, 646, 816, 271, 880, 748, 455, 188, 317, 689, 495,\n",
              "         823, 630, 620, 432, 169, 851, 855, 112, 198, 846, 935, 311, 563, 885,\n",
              "         229, 532, 621, 423, 893, 942, 763, 523, 499, 155, 834,  46, 732, 749,\n",
              "         529, 498, 883, 582, 728, 285, 528, 837, 964, 861, 567, 243, 969, 677,\n",
              "         613, 190, 943, 157, 933, 792, 487, 850, 599, 588, 845, 551, 844, 784,\n",
              "         447, 699, 282, 717, 593, 228, 609, 950, 666, 516, 956, 307, 616, 737,\n",
              "         614, 284, 417, 928, 658, 568, 770, 250, 533, 962, 179, 988, 842,  77,\n",
              "         436, 647, 629, 897, 745, 545, 426, 981, 841, 977, 530, 706, 899, 594,\n",
              "         670, 723, 747, 254, 989, 597, 794, 742, 409, 465, 566, 607, 451, 771,\n",
              "         954, 480, 869, 531, 479,  92, 548, 183, 775, 475, 651, 305, 773, 968,\n",
              "         445, 918, 762, 575, 261, 242, 806, 709, 319, 719, 911, 427, 848, 636,\n",
              "         788, 602, 585,  87, 397, 482, 949, 661, 759, 464, 339, 975, 886, 680,\n",
              "         859, 866, 488, 698, 328, 967, 810, 400, 195, 270, 996, 958, 648, 312,\n",
              "         940, 454, 359,  43, 971, 420, 610, 696, 960, 858, 493, 778,  73, 313,\n",
              "         422, 504, 601, 527, 656, 951, 672, 643, 584, 783, 631, 595, 738,  94,\n",
              "         907, 716, 605, 272, 754, 623, 965, 909, 644, 729, 713, 611, 442, 963,\n",
              "         586,  83, 843, 624, 398, 760, 825, 512, 753, 511, 768, 889, 617, 665,\n",
              "         269, 637, 694, 323, 356,  82,  75, 491, 905, 453, 470, 308, 486, 707,\n",
              "         399, 477, 945, 915, 916, 924, 838, 809, 995, 679, 692, 306, 632, 129,\n",
              "         959, 505,  60, 865, 332, 923,  67, 862,  74, 856, 489, 634, 459, 606,\n",
              "         140, 473, 318, 891,  40, 633,  56, 262, 494, 333, 424, 172, 896, 796,\n",
              "         758, 441,  59, 708, 353, 687, 122, 107, 310, 338, 501,  96, 252, 985,\n",
              "         490, 299, 906, 117, 294, 746, 377, 920, 600, 587, 878, 524, 277, 815,\n",
              "         671,  18, 927, 485, 800, 944, 406, 537, 781, 245, 714, 113, 908, 114,\n",
              "         125, 513, 701, 941, 468,  62, 642, 887, 938, 984, 564, 309, 517, 875,\n",
              "         596, 724, 902, 691, 863, 978, 772, 334,  17, 327, 538, 703, 662, 580,\n",
              "         798, 352, 123, 407, 571, 686, 612,  76, 922, 474,  78, 853, 560, 557,\n",
              "         725, 744, 577, 503,  39, 268, 854, 121, 331, 386, 786, 363, 291, 657,\n",
              "          47, 957, 727, 645,  24, 280, 739, 108, 535, 290, 507,  25, 497, 300,\n",
              "          88,  23,  72, 720,  37, 682, 481,  61, 849, 836, 126, 997, 884, 912,\n",
              "          36, 764, 966, 124, 544, 669, 469, 711, 395, 569, 877, 590, 150,  70,\n",
              "          38,  19, 362, 688, 626, 652, 684, 376, 653, 134,  55,   8,  11, 982,\n",
              "         894, 627, 408,  71, 743, 787,  93, 547, 425,   5, 900, 456, 860, 556,\n",
              "          97, 604, 365, 471, 525, 570, 690, 756, 449, 374,  63, 476, 118, 565,\n",
              "         795, 919, 668,  86, 562, 812, 320, 704, 913, 460,  45,  69,  64, 296,\n",
              "         437, 302, 819, 111, 635, 972, 640, 368, 361,  41, 325, 278, 946, 521,\n",
              "         288, 413, 467, 674, 654,   1, 780, 702, 355, 276,  10, 734, 316, 625,\n",
              "         726, 444,  66, 822, 233, 857, 926, 952, 576,  54, 561, 592, 358, 341,\n",
              "         718, 829,  52, 283, 766, 695, 546, 573, 925, 274, 847, 133, 895,  44,\n",
              "         389, 830,  31, 973, 348, 336, 379,  99, 330, 109, 298,  34, 777, 132,\n",
              "         438,  53, 970,  68, 369, 466, 581, 393, 346, 350, 315, 136, 388, 102,\n",
              "         921, 303, 712,   6, 663, 292,  57,  51, 340, 755, 917, 832, 286,  32,\n",
              "          65, 127, 337, 685, 360, 287,  33, 603, 583, 279, 345, 458, 461,  28,\n",
              "         867, 115, 135, 555,  84,  91, 116,  22, 351, 410, 730, 833, 901,  85,\n",
              "         387, 324, 380, 103,  14,   2, 450,  27, 373, 342, 142, 994, 364, 295,\n",
              "         335,   7,  90, 326, 873, 322, 715, 986, 382,  50, 119, 500, 979, 817,\n",
              "          12, 143, 321, 801, 145,  80, 439, 275, 483, 405, 820, 130, 104,  49,\n",
              "         144, 357, 139, 329,  15, 484, 396, 378, 392,  95,  89,   9, 536, 375,\n",
              "         354, 874, 888,  98, 976, 371,  13, 803, 101, 131, 370,  48,  20,  26,\n",
              "         751, 864, 403, 807, 137, 802, 297,  29,  35,   4, 993,   3, 146,  58,\n",
              "         390, 138,  30,  16, 540, 675, 814, 349, 871, 381, 628, 839, 649, 391,\n",
              "           0, 385, 110, 554, 106, 149,  81, 821, 347, 404, 394, 991, 141, 835,\n",
              "         983, 974, 366, 383, 343,  21, 120, 105, 128, 100, 148, 367, 147, 914,\n",
              "         510, 344, 980, 384, 289, 372]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResNetBlock(nn.Module): # <1>\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim)\n",
        "\n",
        "    def build_conv_block(self, dim):\n",
        "        conv_block = []\n",
        "\n",
        "        conv_block += [nn.ReflectionPad2d(1)]\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
        "                       nn.InstanceNorm2d(dim),\n",
        "                       nn.ReLU(True)]\n",
        "\n",
        "        conv_block += [nn.ReflectionPad2d(1)]\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
        "                       nn.InstanceNorm2d(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_block(x) # <2>\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetGenerator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=9): # <3> \n",
        "\n",
        "        assert(n_blocks >= 0)\n",
        "        super(ResNetGenerator, self).__init__()\n",
        "\n",
        "        self.input_nc = input_nc\n",
        "        self.output_nc = output_nc\n",
        "        self.ngf = ngf\n",
        "\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=True),\n",
        "                 nn.InstanceNorm2d(ngf),\n",
        "                 nn.ReLU(True)]\n",
        "\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**i\n",
        "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
        "                                stride=2, padding=1, bias=True),\n",
        "                      nn.InstanceNorm2d(ngf * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        mult = 2**n_downsampling\n",
        "        for i in range(n_blocks):\n",
        "            model += [ResNetBlock(ngf * mult)]\n",
        "\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**(n_downsampling - i)\n",
        "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                         kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1,\n",
        "                                         bias=True),\n",
        "                      nn.InstanceNorm2d(int(ngf * mult / 2)),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        model += [nn.ReflectionPad2d(3)]\n",
        "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, input): # <3>\n",
        "        return self.model(input)"
      ],
      "metadata": {
        "id": "hWbSEo6PbtUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netG = ResNetGenerator() #making netG model "
      ],
      "metadata": {
        "id": "B11N7zF1u5qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '../horse2zebra_0.4.0.pth'\n",
        "model_data = torch.load(model_path)\n",
        "netG.load_state_dict(model_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "S9qZdDLNvEKM",
        "outputId": "c5987909-72e1-49e5-f158-cd0f1d759c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9f5a851741f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/p1ch2/horse2zebra_0.4.0.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/p1ch2/horse2zebra_0.4.0.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "netG.eval()"
      ],
      "metadata": {
        "id": "Z4q_zfxvvGYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "hgoeJnnnv5UM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}